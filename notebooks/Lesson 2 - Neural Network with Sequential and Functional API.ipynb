{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries import\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put plot of mnist images to showcase each category data and another one for limited size to show its size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n",
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Now in this video we are looking into basic neural network that is fully connected neural network\n",
    "# That's why we should reshape our data\n",
    "x_train = x_train.reshape(-1, 28*28) # -1 represents keep 60000 value same just change last 2 numbers\n",
    "x_test = x_test.reshape(-1, 28*28)\n",
    "print(x_train.dtype)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "float32\n",
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Let's normalise training and testing dataset but why???\n",
    "# 1. Normally if your features are in different scale that leads to issue in training because neural network will inclined towards with features who has large scale values\n",
    "# 2. Large input values are computationaly expensive and memory hungry\n",
    "# 3. It leads to slower convergences of loss function may create problem in accuracy\n",
    "x_train = (x_train / 255.0).astype(\"float32\") # Type casting because by default result of it in float64 type\n",
    "x_test = (x_test / 255.0).astype(\"float32\")\n",
    "\n",
    "print(x_train.dtype)\n",
    "print(x_test.dtype)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internally tensorflow converts numpy array into tensor so we don't have to bother about it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential API (Suitable for simple, not suitable for complex)\n",
    "# It only accept one input and throws one output\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(512, activation=\"relu\", input_shape=(784,)))\n",
    "model.add(layers.Dense(256, activation=\"relu\"))\n",
    "model.add(layers.Dense(10)) # As we have not mentioned any activation function in last layer which is necessary in case of classification\n",
    "# model.add(layers.Dense(10, activation=\"softmax\")) Alternate version\n",
    "\n",
    "# We are going to pass output of last layer from to logit that's why you can see \"from_logits=True\" in loss function\n",
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), optimizer=keras.optimizers.Adam(lr=0.001), metrics=[\"accuracy\"])\n",
    "# model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False), optimizer=keras.optimizers.Adam(lr=0.001), metrics=[\"accuracy\"]) Alternate version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50/50 [==============================] - 1s 20ms/step - loss: 0.5463 - accuracy: 0.8528 - val_loss: 0.2079 - val_accuracy: 0.9426\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.1857 - accuracy: 0.9458 - val_loss: 0.1507 - val_accuracy: 0.9561\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.1265 - accuracy: 0.9638 - val_loss: 0.1088 - val_accuracy: 0.9677\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0939 - accuracy: 0.9731 - val_loss: 0.0946 - val_accuracy: 0.9714\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0733 - accuracy: 0.9787 - val_loss: 0.0867 - val_accuracy: 0.9733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f6199b9760>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=1024, epochs=5, verbose=1, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0879 - accuracy: 0.9728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0879177525639534, 0.9728000164031982]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 256)\n"
     ]
    }
   ],
   "source": [
    "# Debugging model internal layers/ Get particular layer output\n",
    "debug_seq_model = keras.Sequential(model.layers[:-1])\n",
    "features = debug_seq_model.predict(x_test)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 512)\n",
      "(10000, 256)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Get each layer features\n",
    "all_layers_model = keras.Model(inputs=model.inputs, outputs=[layer.output for layer in model.layers])\n",
    "features = all_layers_model.predict(x_test)\n",
    "\n",
    "for feature in features:\n",
    "    print(feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional API (Suitable for both simple and complex architecture)\n",
    "# It only accept one input and throws one output\n",
    "\n",
    "inputs = layers.Input(shape=(784,), name=\"input_layer\")\n",
    "dense = layers.Dense(512, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "dense = layers.Dense(256, activation=\"relu\", name=\"dense_2\")(dense)\n",
    "outputs = layers.Dense(10, activation=\"softmax\", name=\"output_layer\")(dense)\n",
    "\n",
    "functional_model = keras.Model(inputs, outputs)\n",
    "functional_model.compile(loss=keras.losses.SparseCategoricalCrossentropy(), optimizer=keras.optimizers.Adam(lr=0.001), metrics=[\"accuracy\"]) # By default from_logits=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "functional_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50/50 [==============================] - 1s 18ms/step - loss: 0.5416 - accuracy: 0.8523 - val_loss: 0.2009 - val_accuracy: 0.9437\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.1866 - accuracy: 0.9453 - val_loss: 0.1464 - val_accuracy: 0.9581\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.1261 - accuracy: 0.9628 - val_loss: 0.1107 - val_accuracy: 0.9681\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0909 - accuracy: 0.9743 - val_loss: 0.0933 - val_accuracy: 0.9728\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0698 - accuracy: 0.9793 - val_loss: 0.0849 - val_accuracy: 0.9742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f62a0e0700>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functional_model.fit(x_train, y_train, batch_size=1024, epochs=5, verbose=1, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0865 - accuracy: 0.9739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08651512116193771, 0.9739000201225281]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functional_model.evaluate(x_test, y_test, batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 512)\n"
     ]
    }
   ],
   "source": [
    "# Debugging model internal layers/ Get particular layer output\n",
    "debug_func_model = keras.Model(inputs=functional_model.inputs, outputs=[functional_model.get_layer(\"dense_1\").output])\n",
    "features = debug_func_model.predict(x_test)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Try few things\n",
    "1. Try different architecture with larger epochs\n",
    "2. Play with different optimizers\n",
    "3. Layer initializations\n",
    "4. What will happen if we remove data normalization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
